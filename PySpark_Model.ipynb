{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanitising\n",
    "- url address('http:'pattern), twitter ID removing\n",
    "- url address('www.'pattern) removing\n",
    "- lower-case\n",
    "- negation handling\n",
    "- removing numbers and special characters\n",
    "- tokenizing and joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tok = WordPunctTokenizer()\n",
    "\n",
    "pat1 = r'@[A-Za-z0-9_]+'\n",
    "pat2 = r'https?://[^ ]+'\n",
    "combined_pat = r'|'.join((pat1, pat2))\n",
    "www_pat = r'www.[^ ]+'\n",
    "negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
    "                \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
    "                \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
    "                \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
    "                \"mustn't\":\"must not\"}\n",
    "neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')\n",
    "\n",
    "def tweet_cleaner_updated(text):\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    souped = soup.get_text()\n",
    "    try:\n",
    "        bom_removed = souped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "    except:\n",
    "        bom_removed = souped\n",
    "    stripped = re.sub(combined_pat, '', bom_removed)\n",
    "    stripped = re.sub(www_pat, '', stripped)\n",
    "    lower_case = stripped.lower()\n",
    "    neg_handled = neg_pattern.sub(lambda x: negations_dic[x.group()], lower_case)\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", neg_handled)\n",
    "    # During the letters_only process two lines above, it has created unnecessay white spaces,\n",
    "    # I will tokenize and join together to remove unneccessary white spaces\n",
    "    words = [x for x  in tok.tokenize(letters_only) if len(x) > 1]\n",
    "    return (\" \".join(words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1          0  is upset that he can't update his Facebook by ...\n",
       "2          0  @Kenichan I dived many times for the ball. Man...\n",
       "3          0    my whole body feels itchy and like its on fire \n",
       "4          0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/arun/Downloads/CS777/trainingandtestdata/training.1600000.processed.noemoticon.csv\",header=None,\n",
    "                 usecols=[0,5],names=['sentiment','text'],encoding = 'utf-8')\n",
    "df['sentiment'] = df['sentiment'].map({0: 0, 4: 1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning the tweets...\n",
      "\n",
      "Tweets 100000 of 1600000 has been processed\n",
      "Tweets 200000 of 1600000 has been processed\n",
      "Tweets 300000 of 1600000 has been processed\n",
      "Tweets 400000 of 1600000 has been processed\n",
      "Tweets 500000 of 1600000 has been processed\n",
      "Tweets 600000 of 1600000 has been processed\n",
      "Tweets 700000 of 1600000 has been processed\n",
      "Tweets 800000 of 1600000 has been processed\n",
      "Tweets 900000 of 1600000 has been processed\n",
      "Tweets 1000000 of 1600000 has been processed\n",
      "Tweets 1100000 of 1600000 has been processed\n",
      "Tweets 1200000 of 1600000 has been processed\n",
      "Tweets 1300000 of 1600000 has been processed\n",
      "Tweets 1400000 of 1600000 has been processed\n",
      "Tweets 1500000 of 1600000 has been processed\n",
      "Tweets 1600000 of 1600000 has been processed\n",
      "CPU times: user 10min 18s, sys: 37.7 s, total: 10min 56s\n",
      "Wall time: 12min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Cleaning the tweets...\\n\")\n",
    "clean_tweet_texts = []\n",
    "for i in range(0,len(df)):\n",
    "    if( (i+1)%100000 == 0 ):\n",
    "        print(\"Tweets %d of %d has been processed\" % ( i+1, len(df)))                                                                    \n",
    "    clean_tweet_texts.append(tweet_cleaner_updated(df['text'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pd.DataFrame(clean_tweet_texts,columns=['text'])\n",
    "clean_df['target'] = df.sentiment\n",
    "clean_df.to_csv('clean_tweets.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awww that bummer you shoulda got david carr of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can not update his facebook b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dived many times for the ball managed to save ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no it not behaving at all mad why am here beca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  awww that bummer you shoulda got david carr of...       0\n",
       "1  is upset that he can not update his facebook b...       0\n",
       "2  dived many times for the ball managed to save ...       0\n",
       "3     my whole body feels itchy and like its on fire       0\n",
       "4  no it not behaving at all mad why am here beca...       0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv = 'clean_tweets.csv'\n",
    "my_df = pd.read_csv(csv,index_col=0)\n",
    "my_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cleaning the tweets with the updated cleaner function, I took another look at the info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 2 columns):\n",
      "text      1596041 non-null object\n",
      "target    1600000 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 36.6+ MB\n"
     ]
    }
   ],
   "source": [
    "my_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text  target\n",
       "208  NaN       0\n",
       "249  NaN       0\n",
       "282  NaN       0\n",
       "398  NaN       0\n",
       "430  NaN       0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df[my_df.isnull().any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3959"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(my_df.isnull().any(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text       True\n",
       "target    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df.isnull().any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0</td>\n",
       "      <td>1467863072</td>\n",
       "      <td>Mon Apr 06 22:33:25 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Artiel87</td>\n",
       "      <td>@mandayyy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0</td>\n",
       "      <td>1467874569</td>\n",
       "      <td>Mon Apr 06 22:36:27 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Artiel87</td>\n",
       "      <td>@mandayyy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0</td>\n",
       "      <td>1467881474</td>\n",
       "      <td>Mon Apr 06 22:38:20 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>__Susan__</td>\n",
       "      <td>@ITS_NEMESIS -------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>1467912842</td>\n",
       "      <td>Mon Apr 06 22:46:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>KimberlyKane</td>\n",
       "      <td>@danadearmond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>0</td>\n",
       "      <td>1467919452</td>\n",
       "      <td>Mon Apr 06 22:48:48 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jtmal0723</td>\n",
       "      <td>@anistorm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0           1                             2         3             4  \\\n",
       "208  0  1467863072  Mon Apr 06 22:33:25 PDT 2009  NO_QUERY      Artiel87   \n",
       "249  0  1467874569  Mon Apr 06 22:36:27 PDT 2009  NO_QUERY      Artiel87   \n",
       "282  0  1467881474  Mon Apr 06 22:38:20 PDT 2009  NO_QUERY     __Susan__   \n",
       "398  0  1467912842  Mon Apr 06 22:46:53 PDT 2009  NO_QUERY  KimberlyKane   \n",
       "430  0  1467919452  Mon Apr 06 22:48:48 PDT 2009  NO_QUERY     jtmal0723   \n",
       "\n",
       "                         5  \n",
       "208             @mandayyy   \n",
       "249           @mandayyy     \n",
       "282  @ITS_NEMESIS -------   \n",
       "398         @danadearmond   \n",
       "430             @anistorm   "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./trainingandtestdata/training.1600000.processed.noemoticon.csv\",header=None)\n",
    "df.iloc[my_df[my_df.isnull().any(axis=1)].index,:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1596041 entries, 0 to 1596040\n",
      "Data columns (total 2 columns):\n",
      "text      1596041 non-null object\n",
      "target    1596041 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 24.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#Drop these null rows, and update the data frame as they dont contribute to Sentiment Analysis.\n",
    "my_df.dropna(inplace=True)\n",
    "my_df.reset_index(drop=True,inplace=True)\n",
    "my_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF Vectorizer\n",
    "TF-IDF is a way to convert textual data to a numeric form and is short for Term Frequency-Inverse Document Frequency. The vector value it yields is the product of these two terms; TF and IDF.\n",
    "\n",
    "Relative term frequency is calculated for each term within each document as below.\n",
    "\n",
    "$${TF(t,d)} = \\frac {number\\ of\\ times\\ term(t)\\ appears\\ in\\ document(d)}{total\\ number\\ of\\ terms\\ in\\ document(d)}$$\n",
    "For example, if we calculate relative term frequency for 'I' in both document 1 and document 2, it will be as below.\n",
    "\n",
    "$${TF('I',d1)} = \\frac {1}{3} \\approx {0.33}$$$${TF('I',d2)} = \\frac {1}{5} = {0.2}$$\n",
    "Next, we need to get Inverse Document Frequency, which measures how important a word is to differentiate each document by following the calculation as below.\n",
    "\n",
    "$${IDF(t,D)} = \\log \\Big(\\frac {total\\ number\\ of\\ documents(D)}{number\\ of\\ documents\\ with\\ the\\ term(t)\\ in\\ it}\\Big)$$\n",
    "If we calculate inverse document frequency for 'I',\n",
    "\n",
    "$${IDF('I',D)} = \\log \\Big(\\frac {2}{2}\\Big) = {0}$$\n",
    "Once we have the values for TF and IDF, now we can calculate TFIDF as below.\n",
    "\n",
    "$${TFIDF(t,d,D)} = {TF(t,d)}\\cdot{IDF(t,D)}$$\n",
    "Following the case of our example, TFIDF for term 'I' in both documents will be as below.\n",
    "\n",
    "$${TFIDF('I',d1,D)} = {TF('I',d1)}\\cdot{IDF('I',D)} = {0.33}\\times{0} = {0}$$$${TFIDF('I',d2,D)} = {TF('I',d2)}\\cdot{IDF('I',D)} = {0.2}\\times{0} = {0}$$\n",
    "As you can see, the term 'I' appeared equally in both documents, and the TFIDF score is 0, which means the term is not really informative in differentiating documents. The rest is same as count vectorizer, TFIDF vectorizer will calculate these scores for terms in documents, and convert textual data into a numeric form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from time import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "tvec = TfidfVectorizer()\n",
    "cvec = CountVectorizer()\n",
    "lr = LogisticRegression()\n",
    "n_features = np.arange(10000,100001,10000)\n",
    "x = my_df.text\n",
    "y = my_df.target\n",
    "\n",
    "SEED = 2019\n",
    "\n",
    "\n",
    "def accuracy_summary(pipeline, x_train, y_train, x_test, y_test):\n",
    "    if len(x_test[y_test == 0]) / (len(x_test)*1.) > 0.5:\n",
    "        null_accuracy = len(x_test[y_test == 0]) / (len(x_test)*1.)\n",
    "    else:\n",
    "        null_accuracy = 1. - (len(x_test[y_test == 0]) / (len(x_test)*1.))\n",
    "    t0 = time()\n",
    "    sentiment_fit = pipeline.fit(x_train, y_train)\n",
    "    y_pred = sentiment_fit.predict(x_test)\n",
    "    train_test_time = time() - t0\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print (\"null accuracy: {0:.2f}%\".format(null_accuracy*100))\n",
    "    print (\"accuracy score: {0:.2f}%\".format(accuracy*100))\n",
    "    if accuracy > null_accuracy:\n",
    "        print (\"model is {0:.2f}% more accurate than null accuracy\".format((accuracy-null_accuracy)*100))\n",
    "    elif accuracy == null_accuracy:\n",
    "        print (\"model has the same accuracy with the null accuracy\")\n",
    "    else:\n",
    "        print (\"model is {0:.2f}% less accurate than null accuracy\".format((null_accuracy-accuracy)*100))\n",
    "    print (\"train and test time: {0:.2f}s\".format(train_test_time))\n",
    "    print (\"-\"*80)\n",
    "    return accuracy, train_test_time\n",
    "\n",
    "def nfeature_accuracy_checker(vectorizer=cvec, n_features=n_features, stop_words=None, ngram_range=(1, 1), classifier=lr):\n",
    "    result = []\n",
    "    print (classifier)\n",
    "    print (\"\\n\")\n",
    "    for n in n_features:\n",
    "        vectorizer.set_params(stop_words=stop_words, max_features=n, ngram_range=ngram_range)\n",
    "        checker_pipeline = Pipeline([\n",
    "            ('vectorizer', vectorizer),\n",
    "            ('classifier', classifier)\n",
    "        ])\n",
    "        print (\"Validation result for {} features\".format(n))\n",
    "        nfeature_accuracy,tt_time = accuracy_summary(checker_pipeline, x_train, y_train, x_validation, y_validation)\n",
    "        result.append((n,nfeature_accuracy,tt_time))\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering and Model creaton with n-gram approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT FOR UNIGRAM WITH STOP WORDS (Tfidf)\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "Validation result for 10000 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null accuracy: 76.67%\n",
      "accuracy score: 84.81%\n",
      "model is 8.14% more accurate than null accuracy\n",
      "train and test time: 33.52s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 20000 features\n",
      "null accuracy: 76.67%\n",
      "accuracy score: 84.95%\n",
      "model is 8.28% more accurate than null accuracy\n",
      "train and test time: 29.12s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 30000 features\n",
      "null accuracy: 76.67%\n",
      "accuracy score: 85.03%\n",
      "model is 8.36% more accurate than null accuracy\n",
      "train and test time: 37.68s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 40000 features\n",
      "null accuracy: 76.67%\n",
      "accuracy score: 85.05%\n",
      "model is 8.38% more accurate than null accuracy\n",
      "train and test time: 41.25s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 50000 features\n",
      "null accuracy: 76.67%\n",
      "accuracy score: 84.99%\n",
      "model is 8.33% more accurate than null accuracy\n",
      "train and test time: 52.26s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 60000 features\n",
      "null accuracy: 76.67%\n",
      "accuracy score: 84.99%\n",
      "model is 8.33% more accurate than null accuracy\n",
      "train and test time: 47.16s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 70000 features\n",
      "null accuracy: 76.67%\n",
      "accuracy score: 85.00%\n",
      "model is 8.33% more accurate than null accuracy\n",
      "train and test time: 42.44s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 80000 features\n",
      "null accuracy: 76.67%\n",
      "accuracy score: 85.00%\n",
      "model is 8.33% more accurate than null accuracy\n",
      "train and test time: 44.29s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 90000 features\n",
      "null accuracy: 76.67%\n",
      "accuracy score: 85.03%\n",
      "model is 8.36% more accurate than null accuracy\n",
      "train and test time: 39.34s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 100000 features\n",
      "null accuracy: 76.67%\n",
      "accuracy score: 84.99%\n",
      "model is 8.33% more accurate than null accuracy\n",
      "train and test time: 38.30s\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "x_train, x_validation_and_test, y_train, y_validation_and_test = train_test_split(x, y, test_size=.02, random_state=SEED)\n",
    "x_validation, x_test, y_validation, y_test = train_test_split(x_validation_and_test, y_validation_and_test, test_size=.5, random_state=SEED)\n",
    "\n",
    "print (\"RESULT FOR UNIGRAM WITH STOP WORDS (Tfidf)\\n\")\n",
    "feature_result_ugt = nfeature_accuracy_checker(vectorizer=tvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT FOR BIGRAM WITH STOP WORDS (Tfidf)\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "Validation result for 10000 features\n",
      "null accuracy: 76.67%\n",
      "accuracy score: 85.27%\n",
      "model is 8.60% more accurate than null accuracy\n",
      "train and test time: 91.07s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 20000 features\n",
      "null accuracy: 76.67%\n",
      "accuracy score: 85.73%\n",
      "model is 9.06% more accurate than null accuracy\n",
      "train and test time: 68.50s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 30000 features\n",
      "null accuracy: 76.67%\n",
      "accuracy score: 86.00%\n",
      "model is 9.33% more accurate than null accuracy\n",
      "train and test time: 63.77s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 40000 features\n",
      "null accuracy: 76.67%\n",
      "accuracy score: 86.12%\n",
      "model is 9.45% more accurate than null accuracy\n",
      "train and test time: 83.76s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 50000 features\n",
      "null accuracy: 76.67%\n",
      "accuracy score: 86.32%\n",
      "model is 9.65% more accurate than null accuracy\n",
      "train and test time: 90.38s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 60000 features\n",
      "null accuracy: 76.67%\n",
      "accuracy score: 86.41%\n",
      "model is 9.74% more accurate than null accuracy\n",
      "train and test time: 95.48s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 70000 features\n",
      "null accuracy: 76.67%\n",
      "accuracy score: 86.51%\n",
      "model is 9.85% more accurate than null accuracy\n",
      "train and test time: 87.55s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 80000 features\n",
      "null accuracy: 76.67%\n",
      "accuracy score: 86.55%\n",
      "model is 9.88% more accurate than null accuracy\n",
      "train and test time: 81.79s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 90000 features\n",
      "null accuracy: 76.67%\n",
      "accuracy score: 86.64%\n",
      "model is 9.97% more accurate than null accuracy\n",
      "train and test time: 95.45s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 100000 features\n",
      "null accuracy: 76.67%\n",
      "accuracy score: 86.69%\n",
      "model is 10.02% more accurate than null accuracy\n",
      "train and test time: 107.91s\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print (\"RESULT FOR BIGRAM WITH STOP WORDS (Tfidf)\\n\")\n",
    "feature_result_bgt = nfeature_accuracy_checker(vectorizer=tvec,ngram_range=(1, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT FOR TRIGRAM WITH STOP WORDS (Tfidf)\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "Validation result for 10000 features\n",
      "null accuracy: 76.67%\n",
      "accuracy score: 85.42%\n",
      "model is 8.76% more accurate than null accuracy\n",
      "train and test time: 146.96s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 20000 features\n",
      "null accuracy: 76.67%\n",
      "accuracy score: 85.68%\n",
      "model is 9.01% more accurate than null accuracy\n",
      "train and test time: 183.25s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 30000 features\n",
      "null accuracy: 76.67%\n",
      "accuracy score: 85.83%\n",
      "model is 9.17% more accurate than null accuracy\n",
      "train and test time: 173.98s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 40000 features\n",
      "null accuracy: 76.67%\n",
      "accuracy score: 85.95%\n",
      "model is 9.28% more accurate than null accuracy\n",
      "train and test time: 181.20s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 50000 features\n",
      "null accuracy: 76.67%\n",
      "accuracy score: 86.08%\n",
      "model is 9.42% more accurate than null accuracy\n",
      "train and test time: 163.31s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 60000 features\n",
      "null accuracy: 76.67%\n",
      "accuracy score: 86.15%\n",
      "model is 9.48% more accurate than null accuracy\n",
      "train and test time: 140.55s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 70000 features\n",
      "null accuracy: 76.67%\n",
      "accuracy score: 86.31%\n",
      "model is 9.64% more accurate than null accuracy\n",
      "train and test time: 157.50s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 80000 features\n",
      "null accuracy: 76.67%\n",
      "accuracy score: 86.27%\n",
      "model is 9.61% more accurate than null accuracy\n",
      "train and test time: 151.11s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 90000 features\n",
      "null accuracy: 76.67%\n",
      "accuracy score: 86.23%\n",
      "model is 9.56% more accurate than null accuracy\n",
      "train and test time: 141.36s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for 100000 features\n",
      "null accuracy: 76.67%\n",
      "accuracy score: 86.39%\n",
      "model is 9.72% more accurate than null accuracy\n",
      "train and test time: 162.08s\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print (\"RESULT FOR TRIGRAM WITH STOP WORDS (Tfidf)\\n\")\n",
    "feature_result_tgt = nfeature_accuracy_checker(vectorizer=tvec,ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PySpark Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark as ps\n",
    "import warnings\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "try:\n",
    "    sc = ps.SparkContext('local[4]')\n",
    "    sqlContext = SQLContext(sc)\n",
    "except ValueError:\n",
    "    warnings.warn(\"SparkContext already exists in this scope\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'local[4]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('./clean_tweets.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+------+\n",
      "|_c0|                text|target|\n",
      "+---+--------------------+------+\n",
      "|  0|awww that bummer ...|     0|\n",
      "|  1|is upset that he ...|     0|\n",
      "|  2|dived many times ...|     0|\n",
      "|  3|my whole body fee...|     0|\n",
      "|  4|no it not behavin...|     0|\n",
      "+---+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1596041"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference:\n",
    "***\n",
    "\n",
    "- After dropping NA, there are less than 1.6 million Tweets. \n",
    "- 1% for validation \n",
    "- 1% for test \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_set, val_set, test_set) = df.randomSplit([0.98, 0.01, 0.01], seed = 2019)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, CountVectorizer\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+------+--------------------+--------------------+--------------------+-----+\n",
      "|_c0|                text|target|               words|                  tf|            features|label|\n",
      "+---+--------------------+------+--------------------+--------------------+--------------------+-----+\n",
      "|  0|awww that bummer ...|     0|[awww, that, bumm...|(65536,[8436,8847...|(65536,[8436,8847...|  0.0|\n",
      "|  1|is upset that he ...|     0|[is, upset, that,...|(65536,[1444,2071...|(65536,[1444,2071...|  0.0|\n",
      "|  2|dived many times ...|     0|[dived, many, tim...|(65536,[2548,2888...|(65536,[2548,2888...|  0.0|\n",
      "|  3|my whole body fee...|     0|[my, whole, body,...|(65536,[158,11650...|(65536,[158,11650...|  0.0|\n",
      "|  4|no it not behavin...|     0|[no, it, not, beh...|(65536,[1968,4488...|(65536,[1968,4488...|  0.0|\n",
      "+---+--------------------+------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashtf = HashingTF(numFeatures=2**16, inputCol=\"words\", outputCol='tf')\n",
    "idf = IDF(inputCol='tf', outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "label_stringIdx = StringIndexer(inputCol = \"target\", outputCol = \"label\")\n",
    "pipeline = Pipeline(stages=[tokenizer, hashtf, idf, label_stringIdx])\n",
    "\n",
    "pipelineFit = pipeline.fit(train_set)\n",
    "train_df = pipelineFit.transform(train_set)\n",
    "val_df = pipelineFit.transform(val_set)\n",
    "train_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.3 ms, sys: 24 ms, total: 56.3 ms\n",
      "Wall time: 56.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(maxIter=100)\n",
    "lrModel = lr.fit(train_df)\n",
    "predictions = lrModel.transform(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8604517918379164"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'areaUnderROC'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.getMetricName()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7956\n",
      "ROC-AUC: 0.8657\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "cv = CountVectorizer(vocabSize=2**16, inputCol=\"words\", outputCol='cv')\n",
    "idf = IDF(inputCol='cv', outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "label_stringIdx = StringIndexer(inputCol = \"target\", outputCol = \"label\")\n",
    "lr = LogisticRegression(maxIter=100)\n",
    "pipeline = Pipeline(stages=[tokenizer, cv, idf, label_stringIdx, lr])\n",
    "\n",
    "pipelineFit = pipeline.fit(train_set)\n",
    "predictions = pipelineFit.transform(val_set)\n",
    "accuracy = predictions.filter(predictions.label == predictions.prediction).count() / float(val_set.count())\n",
    "roc_auc = evaluator.evaluate(predictions)\n",
    "\n",
    "print (\"Accuracy Score: {0:.4f}\".format(accuracy))\n",
    "print (\"ROC-AUC: {0:.4f}\".format(roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import NGram, VectorAssembler\n",
    "\n",
    "def build_ngrams_wocs(inputCol=[\"text\",\"target\"], n=3):\n",
    "    tokenizer = [Tokenizer(inputCol=\"text\", outputCol=\"words\")]\n",
    "    ngrams = [\n",
    "        NGram(n=i, inputCol=\"words\", outputCol=\"{0}_grams\".format(i))\n",
    "        for i in range(1, n + 1)\n",
    "    ]\n",
    "\n",
    "    cv = [\n",
    "        CountVectorizer(vocabSize=5460,inputCol=\"{0}_grams\".format(i),\n",
    "            outputCol=\"{0}_tf\".format(i))\n",
    "        for i in range(1, n + 1)\n",
    "    ]\n",
    "    idf = [IDF(inputCol=\"{0}_tf\".format(i), outputCol=\"{0}_tfidf\".format(i), minDocFreq=5) for i in range(1, n + 1)]\n",
    "\n",
    "    assembler = [VectorAssembler(\n",
    "        inputCols=[\"{0}_tfidf\".format(i) for i in range(1, n + 1)],\n",
    "        outputCol=\"features\"\n",
    "    )]\n",
    "    label_stringIdx = [StringIndexer(inputCol = \"target\", outputCol = \"label\")]\n",
    "    lr = [LogisticRegression(maxIter=100)]\n",
    "    return Pipeline(stages=tokenizer + ngrams + cv + idf+ assembler + label_stringIdx+lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8110\n",
      "ROC-AUC: 0.8835\n"
     ]
    }
   ],
   "source": [
    "trigramwocs_pipelineFit = build_ngrams_wocs().fit(train_set)\n",
    "predictions_wocs = trigramwocs_pipelineFit.transform(val_set)\n",
    "accuracy_wocs = predictions_wocs.filter(predictions_wocs.label == predictions_wocs.prediction).count() / float(val_set.count())\n",
    "roc_auc_wocs = evaluator.evaluate(predictions_wocs)\n",
    "\n",
    "# print accuracy, roc_auc\n",
    "print (\"Accuracy Score: {0:.4f}\".format(accuracy_wocs))\n",
    "print (\"ROC-AUC: {0:.4f}\".format(roc_auc_wocs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference:\n",
    "***\n",
    "- TF-IDF + Logistic Regression produced an accuracy of 86.04\n",
    "- CountVectorizer + Logistic Regression produced an accuracy of 86.57\n",
    "- N-Gram model produced an accuracy of 88.35\n",
    "\n",
    "Since  N-Gram model produced the best results, proceeding with N-Gram model on making the predictions on Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8120\n",
      "ROC-AUC: 0.8838\n"
     ]
    }
   ],
   "source": [
    "test_predictions = trigramwocs_pipelineFit.transform(test_set)\n",
    "test_accuracy = test_predictions.filter(test_predictions.label == test_predictions.prediction).count() / float(test_set.count())\n",
    "test_roc_auc = evaluator.evaluate(test_predictions)\n",
    "\n",
    "# print accuracy, roc_auc\n",
    "print (\"Accuracy Score: {0:.4f}\".format(test_accuracy))\n",
    "print (\"ROC-AUC: {0:.4f}\".format(test_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Test Accuracy is 88.38%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
